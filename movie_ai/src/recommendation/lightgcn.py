"""
LightGCN æ¨èå™¨å®ç°
ä½¿ç”¨ PyTorch Geometric çš„ LGConv å±‚å®ç° LightGCN
é›†æˆç”¨æˆ·è¡Œä¸ºè¿½è¸ªï¼Œæ”¯æŒåŠ¨æ€æ¨è
"""
import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import LGConv
from torch_geometric.data import Data
from sklearn.metrics.pairwise import cosine_similarity
from user_behavior import UserBehaviorTracker


class LightGCN(nn.Module):
    """
    LightGCN å›¾ç¥ç»ç½‘ç»œæ¨¡å‹
    """
    def __init__(self, num_users, num_items, embed_dim=64, num_layers=3):
        super(LightGCN, self).__init__()
        self.num_users = num_users
        self.num_items = num_items
        self.embed_dim = embed_dim
        self.num_layers = num_layers
        
        # ç”¨æˆ·å’Œç‰©å“çš„åˆå§‹åµŒå…¥
        self.user_embedding = nn.Embedding(num_users, embed_dim)
        self.item_embedding = nn.Embedding(num_items, embed_dim)
        
        # åˆå§‹åŒ–åµŒå…¥æƒé‡
        nn.init.normal_(self.user_embedding.weight, std=0.1)
        nn.init.normal_(self.item_embedding.weight, std=0.1)
        
        # LightGCN å·ç§¯å±‚
        self.convs = nn.ModuleList([
            LGConv(normalize=True) for _ in range(num_layers)
        ])
    
    def forward(self, edge_index):
        """
        å‰å‘ä¼ æ’­ï¼Œè®¡ç®—ç”¨æˆ·å’Œç‰©å“çš„æœ€ç»ˆåµŒå…¥
        """
        # è·å–åˆå§‹åµŒå…¥
        user_emb = self.user_embedding.weight
        item_emb = self.item_embedding.weight
        
        # åˆå¹¶æ‰€æœ‰èŠ‚ç‚¹åµŒå…¥
        all_emb = torch.cat([user_emb, item_emb], dim=0)
        
        # åˆå§‹åŒ–åµŒå…¥åˆ—è¡¨ï¼ˆç”¨äºå±‚èšåˆï¼‰
        embs = [all_emb]
        
        # é€šè¿‡æ‰€æœ‰å·ç§¯å±‚
        for conv in self.convs:
            all_emb = conv(all_emb, edge_index)
            embs.append(all_emb)
        
        # ç®€å•å¹³å‡èšåˆæ‰€æœ‰å±‚çš„åµŒå…¥
        final_emb = torch.stack(embs, dim=0).mean(dim=0)
        
        # åˆ†ç¦»ç”¨æˆ·å’Œç‰©å“åµŒå…¥
        user_final_emb = final_emb[:self.num_users]
        item_final_emb = final_emb[self.num_users:]
        
        return user_final_emb, item_final_emb
    
    def predict(self, user_ids, item_ids, edge_index):
        """
        é¢„æµ‹ç”¨æˆ·å¯¹ç‰©å“çš„è¯„åˆ†
        """
        user_emb, item_emb = self.forward(edge_index)
        user_emb = user_emb[user_ids]
        item_emb = item_emb[item_ids]
        
        # ä½¿ç”¨å†…ç§¯è®¡ç®—åˆ†æ•°
        scores = (user_emb * item_emb).sum(dim=-1)
        return scores


class LightGCNRecommender:
    """
    LightGCN æ¨èå™¨åŒ…è£…ç±»
    è´Ÿè´£è®­ç»ƒã€ä¿å­˜æ¨¡å‹ã€æä¾›æ¨èæœåŠ¡
    é›†æˆç”¨æˆ·è¡Œä¸ºè¿½è¸ªï¼Œæ”¯æŒåŠ¨æ€æ¨è
    """
    def __init__(self, embed_dim=64, num_layers=3, model_dir='d:/code/vue/movie_ai/data',
                 use_behavior_tracking=True, decay_days=30):
        self.embed_dim = embed_dim
        self.num_layers = num_layers
        self.model_dir = model_dir
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.item_embeddings = None
        self.user_embeddings = None
        
        # ç”¨æˆ·è¡Œä¸ºè¿½è¸ª
        self.use_behavior_tracking = use_behavior_tracking
        self.behavior_tracker = None
        self.decay_days = decay_days
        
        # è¯„åˆ†æ•°æ®ï¼ˆç”¨äºç»Ÿè®¡çƒ­é—¨ç”µå½±ï¼‰
        self.ratings_data = None
        self.num_users = 0
        self.num_items = 0
        
        # åˆ›å»ºæ¨¡å‹ç›®å½•
        os.makedirs(model_dir, exist_ok=True)
    
    def _load_movielens_data(self, ml100k_path):
        """
        åŠ è½½ MovieLens 100K æ•°æ®é›†
        """
        ratings_file = os.path.join(ml100k_path, 'u.data')
        
        # è¯»å–è¯„åˆ†æ•°æ®
        ratings = []
        users = set()
        items = set()
        
        with open(ratings_file, 'r') as f:
            for line in f:
                user_id, item_id, rating, timestamp = line.strip().split('\t')
                user_id = int(user_id) - 1  # ä» 1-based è½¬ä¸º 0-based
                item_id = int(item_id) - 1
                rating = float(rating)
                
                ratings.append((user_id, item_id, rating))
                users.add(user_id)
                items.add(item_id)
        
        num_users = max(users) + 1
        num_items = max(items) + 1
        
        print(f"åŠ è½½æ•°æ®é›†: {len(ratings)} æ¡è¯„åˆ†, {num_users} ç”¨æˆ·, {num_items} ç‰©å“")
        
        return ratings, num_users, num_items
    
    def _build_graph(self, ratings, num_users, num_items, min_rating=4.0):
        """
        æ„å»ºç”¨æˆ·-ç‰©å“äºŒéƒ¨å›¾
        åªæœ‰è¯„åˆ† >= min_rating çš„è¾¹æ‰è¢«ä¿ç•™
        """
        # è¿‡æ»¤é«˜è¯„åˆ†æ•°æ®
        filtered_ratings = [(u, i, r) for u, i, r in ratings if r >= min_rating]
        
        # æ„å»ºè¾¹ç´¢å¼•
        edge_index = []
        for user_id, item_id, rating in filtered_ratings:
            # ç”¨æˆ· -> ç‰©å“
            edge_index.append([user_id, num_users + item_id])
            # ç‰©å“ -> ç”¨æˆ· (åŒå‘)
            edge_index.append([num_users + item_id, user_id])
        
        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        
        print(f"æ„å»ºå›¾: {len(filtered_ratings)} æ¡è¾¹ ({2 * len(filtered_ratings)} æ¡åŒå‘è¾¹)")
        
        return edge_index, len(filtered_ratings)
    
    def train(self, ml100k_path, epochs=50, lr=0.001, batch_size=1024, min_rating=4.0, 
              validation_split=0.2):
        """
        è®­ç»ƒ LightGCN æ¨¡å‹
        
        å‚æ•°:
            validation_split: éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤ 0.2)
            
        è¿”å›:
            train_losses: è®­ç»ƒæŸå¤±åˆ—è¡¨
            val_losses: éªŒè¯æŸå¤±åˆ—è¡¨
        """
        print("å¼€å§‹è®­ç»ƒ LightGCN æ¨¡å‹...")
        
        # åŠ è½½æ•°æ®
        ratings, num_users, num_items = self._load_movielens_data(ml100k_path)
        
        # ä¿å­˜è¯„åˆ†æ•°æ®ç”¨äºç»Ÿè®¡
        self.ratings_data = ratings
        self.num_users = num_users
        self.num_items = num_items

        # ä¿å­˜è¯„åˆ†æ•°æ®åˆ°æ–‡ä»¶ï¼ˆç”¨äºæŒä¹…åŒ–ï¼‰
        self.save_ratings_data()
        
        edge_index, num_edges = self._build_graph(ratings, num_users, num_items, min_rating)
        
        # åˆ›å»ºæ¨¡å‹
        self.model = LightGCN(
            num_users=num_users,
            num_items=num_items,
            embed_dim=self.embed_dim,
            num_layers=self.num_layers
        ).to(self.device)
        
        # ç§»åŠ¨è¾¹åˆ°è®¾å¤‡
        edge_index = edge_index.to(self.device)
        
        # ä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
        
        # å‡†å¤‡æ•°æ®
        all_data = [(u, i, r) for u, i, r in ratings if r >= min_rating]
        
        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        np.random.seed(42)
        np.random.shuffle(all_data)
        split_idx = int(len(all_data) * (1 - validation_split))
        train_data = all_data[:split_idx]
        val_data = all_data[split_idx:]
        
        train_losses = []
        val_losses = []
        
        print(f"è®­ç»ƒå‚æ•°: epochs={epochs}, lr={lr}, batch_size={batch_size}")
        print(f"æ•°æ®åˆ’åˆ†: è®­ç»ƒé›†={len(train_data)}, éªŒè¯é›†={len(val_data)}")
        print(f"è®¾å¤‡: {self.device}")
        print("-" * 50)
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            self.model.train()
            total_loss = 0
            
            # å°æ‰¹é‡è®­ç»ƒ
            for i in range(0, len(train_data), batch_size):
                batch = train_data[i:i + batch_size]
                user_ids = torch.tensor([u for u, _, _ in batch], dtype=torch.long).to(self.device)
                item_ids = torch.tensor([i for _, i, _ in batch], dtype=torch.long).to(self.device)
                ratings_tensor = torch.tensor([r for _, _, r in batch], dtype=torch.float).to(self.device)
                
                # é¢„æµ‹è¯„åˆ†
                optimizer.zero_grad()
                predictions = self.model.predict(user_ids, item_ids, edge_index)
                
                # è®¡ç®—æŸå¤± (BPR Loss è¿‘ä¼¼)
                # è¿™é‡Œç®€åŒ–ä¸º MSE Loss
                loss = F.mse_loss(predictions, ratings_tensor)
                
                # æ·»åŠ  L2 æ­£åˆ™åŒ–
                l2_reg = (
                    self.model.user_embedding.weight.norm() + 
                    self.model.item_embedding.weight.norm()
                ) * 0.001
                loss += l2_reg
                
                # åå‘ä¼ æ’­
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
            
            # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
            avg_train_loss = total_loss / (len(train_data) / batch_size)
            train_losses.append(avg_train_loss)
            
            # éªŒè¯é˜¶æ®µ
            self.model.eval()
            val_loss = 0
            with torch.no_grad():
                for i in range(0, len(val_data), batch_size):
                    batch = val_data[i:i + batch_size]
                    user_ids = torch.tensor([u for u, _, _ in batch], dtype=torch.long).to(self.device)
                    item_ids = torch.tensor([i for _, i, _ in batch], dtype=torch.long).to(self.device)
                    ratings_tensor = torch.tensor([r for _, _, r in batch], dtype=torch.float).to(self.device)
                    
                    predictions = self.model.predict(user_ids, item_ids, edge_index)
                    loss = F.mse_loss(predictions, ratings_tensor)
                    val_loss += loss.item()
            
            avg_val_loss = val_loss / (len(val_data) / batch_size)
            val_losses.append(avg_val_loss)
            
            # æ‰“å°è¿›åº¦
            if (epoch + 1) % 10 == 0 or epoch == 0:
                print(f"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")
        
        print("-" * 50)
        print("è®­ç»ƒå®Œæˆï¼")
        
        # æå–å¹¶ä¿å­˜åµŒå…¥
        self._save_embeddings(edge_index)
        
        return train_losses, val_losses
    
    def _save_embeddings(self, edge_index):
        """
        æå–å¹¶ä¿å­˜ç”¨æˆ·å’Œç‰©å“çš„åµŒå…¥
        """
        self.model.eval()
        with torch.no_grad():
            user_emb, item_emb = self.model.forward(edge_index)
            
            # è½¬æ¢ä¸º numpy å¹¶ä¿å­˜
            self.user_embeddings = user_emb.cpu().numpy()
            self.item_embeddings = item_emb.cpu().numpy()
            
            # ä¿å­˜åµŒå…¥æ–‡ä»¶
            user_emb_path = os.path.join(self.model_dir, 'lightgcn_user_embeddings.npy')
            item_emb_path = os.path.join(self.model_dir, 'lightgcn_item_embeddings.npy')
            
            np.save(user_emb_path, self.user_embeddings)
            np.save(item_emb_path, self.item_embeddings)
            
            print(f"ç”¨æˆ·åµŒå…¥å·²ä¿å­˜: {user_emb_path}")
            print(f"ç‰©å“åµŒå…¥å·²ä¿å­˜: {item_emb_path}")
            
            # åˆå§‹åŒ–è¡Œä¸ºè¿½è¸ªå™¨
            if self.use_behavior_tracking:
                self._init_behavior_tracker()
    
    def _init_behavior_tracker(self):
        """
        åˆå§‹åŒ–ç”¨æˆ·è¡Œä¸ºè¿½è¸ªå™¨
        ä½¿ç”¨ç”µå½±åµŒå…¥ä½œä¸ºåŸºç¡€
        """
        if self.item_embeddings is None:
            print("è­¦å‘Š: ç‰©å“åµŒå…¥æœªåŠ è½½ï¼Œæ— æ³•åˆå§‹åŒ–è¡Œä¸ºè¿½è¸ªå™¨")
            return

        # æ„å»ºç”µå½±IDåˆ°å‘é‡çš„æ˜ å°„
        movie_embeddings = {i: self.item_embeddings[i] for i in range(len(self.item_embeddings))}

        # åˆ›å»ºè¡Œä¸ºè¿½è¸ªå™¨
        # ä½¿ç”¨ä¸å‰ç«¯åŒ¹é…çš„0-10åˆ†åˆ¶è¯„åˆ†æƒé‡ï¼Œæ˜ å°„åˆ°ä¸‰ä¸ªç­‰çº§
        self.behavior_tracker = UserBehaviorTracker(
            decay_days=self.decay_days,
            persist_dir=self.model_dir,  # æŒä¹…åŒ–ç›®å½•
            behavior_weights={
                'like': 1.0,             # ğŸ‘ å–œæ¬¢ - æœ€é«˜æƒé‡
                'favorite': 0.8,         # â­ æ”¶è—
                'rate_high': 0.7,        # é«˜è¯„åˆ† (8-10åˆ†)
                'rate_medium': 0.5,      # ä¸­è¯„åˆ† (5-7åˆ†)
                'rate_low': 0.3,         # ä½è¯„åˆ† (1-4åˆ†)
                'click': 0.3,            # ğŸ‘† ç‚¹å‡» - æœ€ä½æƒé‡
                'view': 0.3,             # è§‚çœ‹
                'watch': 0.6,            # å®Œæ•´è§‚çœ‹
                'share': 0.6,            # ğŸ“¤ åˆ†äº«
                'comment': 0.5,          # ğŸ’¬ è¯„è®º
            }
        )
        # è®¾ç½®ç”µå½±åµŒå…¥
        self.behavior_tracker.set_movie_embeddings(movie_embeddings)
        self.behavior_tracker.set_movie_embeddings(movie_embeddings)
        
        print(f"âœ“ è¡Œä¸ºè¿½è¸ªå™¨å·²åˆå§‹åŒ– (è¡°å‡å¤©æ•°: {self.decay_days})")
    
    def record_user_behavior(self, user_id, movie_id, behavior_type, metadata=None):
        """
        è®°å½•ç”¨æˆ·è¡Œä¸º
        
        å‚æ•°:
            user_id: ç”¨æˆ·ID (int)
            movie_id: ç”µå½±ID (int, 0-based)
            behavior_type: è¡Œä¸ºç±»å‹ (str)
                - click: ç‚¹å‡»/æµè§ˆ
                - view: è§‚çœ‹
                - favorite: æ”¶è—/å–œæ¬¢
                - watch: å®Œæ•´è§‚çœ‹
                - rate: è¯„åˆ† (éœ€åœ¨ metadata ä¸­æä¾› rating å€¼)
                - share: åˆ†äº«
            metadata: é¢å¤–å…ƒæ•°æ® (dict)
                - rating: è¯„åˆ†å€¼ (1-5)
                - watch_duration: è§‚çœ‹æ—¶é•¿
                ç­‰
        
        è¿”å›:
            bool: æ˜¯å¦è®°å½•æˆåŠŸ
        """
        if not self.use_behavior_tracking:
            print("è­¦å‘Š: è¡Œä¸ºè¿½è¸ªæœªå¯ç”¨")
            return False
        
        if self.behavior_tracker is None:
            print("è­¦å‘Š: è¡Œä¸ºè¿½è¸ªå™¨æœªåˆå§‹åŒ–")
            return False
        
        return self.behavior_tracker.record_behavior(user_id, movie_id, behavior_type, metadata)
    
    def load_embeddings(self):
        """
        ä»æ–‡ä»¶åŠ è½½é¢„è®­ç»ƒçš„åµŒå…¥
        """
        user_emb_path = os.path.join(self.model_dir, 'lightgcn_user_embeddings.npy')
        item_emb_path = os.path.join(self.model_dir, 'lightgcn_item_embeddings.npy')

        if os.path.exists(user_emb_path) and os.path.exists(item_emb_path):
            self.user_embeddings = np.load(user_emb_path)
            self.item_embeddings = np.load(item_emb_path)
            print(f"å·²åŠ è½½é¢„è®­ç»ƒåµŒå…¥: ç”¨æˆ·={self.user_embeddings.shape}, ç‰©å“={self.item_embeddings.shape}")

            # åŠ è½½è¯„åˆ†æ•°æ®
            self.load_ratings_data()

            # å°†ç”µå½±åµŒå…¥è®¾ç½®åˆ°è¡Œä¸ºè¿½è¸ªå™¨
            if self.use_behavior_tracking:
                self._init_behavior_tracker()

            return True
        else:
            print("æœªæ‰¾åˆ°é¢„è®­ç»ƒåµŒå…¥æ–‡ä»¶ï¼Œéœ€è¦å…ˆè®­ç»ƒæ¨¡å‹")
            return False
    
    def recommend(self, user_history, top_k=10, exclude_seen=True, user_id=None, use_dynamic=False):
        """
        åŸºäºç”¨æˆ·å†å²æ¨èç”µå½±
        
        å‚æ•°:
            user_history: ç”¨æˆ·å†å²è§‚çœ‹çš„ç”µå½± ID åˆ—è¡¨ï¼ˆ0-basedï¼‰
            top_k: è¿”å› top-k æ¨è
            exclude_seen: æ˜¯å¦æ’é™¤å·²çœ‹è¿‡çš„ç”µå½±
            user_id: ç”¨æˆ·ID (ç”¨äºåŠ¨æ€æ¨è)
            use_dynamic: æ˜¯å¦ä½¿ç”¨åŠ¨æ€ç”¨æˆ·å‘é‡æ¨è
        
        è¿”å›:
            List[Tuple[int, float]]: [(movie_id, score), ...]
        """
        if self.item_embeddings is None:
            raise ValueError("éœ€è¦å…ˆè®­ç»ƒæ¨¡å‹æˆ–åŠ è½½åµŒå…¥")
        
        # å°è¯•ä½¿ç”¨åŠ¨æ€æ¨è
        if use_dynamic and user_id is not None and self.use_behavior_tracking:
            if self.behavior_tracker is not None:
                return self._recommend_dynamic(user_id, top_k, exclude_seen, user_history)
        
        # å¦‚æœç”¨æˆ·æ²¡æœ‰å†å²è®°å½•ï¼Œè¿”å›çƒ­é—¨ç”µå½±
        if not user_history:
            return self._get_popular_movies(top_k)
        
        # è®¡ç®—ç”¨æˆ·å†å²ä¸­æ‰€æœ‰ç”µå½±çš„å¹³å‡åµŒå…¥ä½œä¸ºç”¨æˆ·ç”»åƒ
        user_emb = np.mean([self.item_embeddings[mid] for mid in user_history if mid < len(self.item_embeddings)], axis=0)
        
        # è®¡ç®—æ‰€æœ‰ç”µå½±çš„ç›¸ä¼¼åº¦
        similarities = cosine_similarity([user_emb], self.item_embeddings)[0]
        
        # æ’é™¤å·²çœ‹è¿‡çš„ç”µå½±
        if exclude_seen:
            for mid in user_history:
                if mid < len(similarities):
                    similarities[mid] = -1
        
        # è·å– top-k
        top_indices = np.argsort(similarities)[::-1][:top_k]
        top_scores = similarities[top_indices]
        
        return list(zip(top_indices.tolist(), top_scores.tolist()))
    
    def _recommend_dynamic(self, user_id, top_k=10, exclude_seen=True, user_history=None):
        """
        åŸºäºåŠ¨æ€ç”¨æˆ·å‘é‡æ¨èç”µå½±ï¼ˆæ¨èç»™æœ‰è¡Œä¸ºè®°å½•çš„ç”¨æˆ·ï¼‰

        å‚æ•°:
            user_id: ç”¨æˆ·ID
            top_k: è¿”å› top-k æ¨è
            exclude_seen: æ˜¯å¦æ’é™¤å·²çœ‹è¿‡çš„ç”µå½±
            user_history: ç”¨æˆ·å†å²ï¼ˆç”¨äºæ’é™¤ï¼‰

        è¿”å›:
            List[Tuple[int, float]]: [(movie_id, score), ...]
        """
        if self.item_embeddings is None:
            raise ValueError("éœ€è¦å…ˆè®­ç»ƒæ¨¡å‹æˆ–åŠ è½½åµŒå…¥")

        if self.behavior_tracker is None:
            raise ValueError("è¡Œä¸ºè¿½è¸ªå™¨æœªåˆå§‹åŒ–")

        # è·å–é¢„è®­ç»ƒç”¨æˆ·åµŒå…¥
        pretrained_emb = None
        if self.user_embeddings is not None and user_id < len(self.user_embeddings):
            pretrained_emb = self.user_embeddings[user_id]

        # è®¡ç®—åŠ¨æ€ç”¨æˆ·å‘é‡ï¼ˆåŠ æƒèåˆé¢„è®­ç»ƒåµŒå…¥å’Œè¡Œä¸ºå‘é‡ï¼‰
        user_emb = self.behavior_tracker.compute_user_vector(
            user_id,
            pretrained_embedding=pretrained_emb
        )

        # å¦‚æœæ²¡æœ‰è¡Œä¸ºæ•°æ®ä¸”æ²¡æœ‰é¢„è®­ç»ƒåµŒå…¥ï¼Œå›é€€åˆ°é™æ€æ¨è
        if user_emb is None:
            print(f"ç”¨æˆ· {user_id} è¡Œä¸ºæ•°æ®ä¸è¶³ä¸”æ— é¢„è®­ç»ƒåµŒå…¥ï¼Œä½¿ç”¨é™æ€æ¨è")
            if user_history:
                return self.recommend(user_history, top_k, exclude_seen)
            else:
                return self._get_popular_movies(top_k)
        
        # è®¡ç®—æ‰€æœ‰ç”µå½±çš„ç›¸ä¼¼åº¦
        similarities = cosine_similarity([user_emb], self.item_embeddings)[0]
        
        # æ’é™¤å·²çœ‹è¿‡çš„ç”µå½±
        if exclude_seen:
            # æ’é™¤å†å²è®°å½•ä¸­çš„ç”µå½±
            if user_history:
                for mid in user_history:
                    if mid < len(similarities):
                        similarities[mid] = -1
            
            # æ’é™¤è¡Œä¸ºè®°å½•ä¸­çš„ç”µå½±
            if user_id in self.behavior_tracker.user_behaviors:
                for movie_id in self.behavior_tracker.user_behaviors[user_id].keys():
                    if movie_id < len(similarities):
                        similarities[movie_id] = -1
        
        # è·å– top-k
        top_indices = np.argsort(similarities)[::-1][:top_k]
        top_scores = similarities[top_indices]

        return list(zip(top_indices.tolist(), top_scores.tolist()))

    def save_ratings_data(self):
        """
        ä¿å­˜è¯„åˆ†æ•°æ®åˆ°æ–‡ä»¶
        """
        if self.ratings_data is None:
            return False

        try:
            ratings_path = os.path.join(self.model_dir, 'lightgcn_ratings_data.npy')
            # ä½¿ç”¨ object ç±»å‹ä¿å­˜åˆ—è¡¨æ•°æ®
            np.save(ratings_path, np.array(self.ratings_data, dtype=object))
            print(f"å·²ä¿å­˜è¯„åˆ†æ•°æ®: {len(self.ratings_data)} æ¡è®°å½•")
            return True
        except Exception as e:
            print(f"ä¿å­˜è¯„åˆ†æ•°æ®å¤±è´¥: {e}")
            return False

    def load_ratings_data(self):
        """
        ä»æ–‡ä»¶åŠ è½½è¯„åˆ†æ•°æ®
        """
        try:
            ratings_path = os.path.join(self.model_dir, 'lightgcn_ratings_data.npy')
            if os.path.exists(ratings_path):
                self.ratings_data = list(np.load(ratings_path, allow_pickle=True))
                print(f"å·²åŠ è½½è¯„åˆ†æ•°æ®: {len(self.ratings_data)} æ¡è®°å½•")
                return True
            else:
                print("æœªæ‰¾åˆ°è¯„åˆ†æ•°æ®æ–‡ä»¶")
                return False
        except Exception as e:
            print(f"åŠ è½½è¯„åˆ†æ•°æ®å¤±è´¥: {e}")
            return False

    def find_similar_movies(self, movie_id, top_k=10):
        """
        æŸ¥æ‰¾ä¸æŒ‡å®šç”µå½±ç›¸ä¼¼çš„ç”µå½±
        
        å‚æ•°:
            movie_id: ç”µå½± IDï¼ˆ0-basedï¼‰
            top_k: è¿”å› top-k ç›¸ä¼¼ç”µå½±
        """
        if self.item_embeddings is None:
            raise ValueError("éœ€è¦å…ˆè®­ç»ƒæ¨¡å‹æˆ–åŠ è½½åµŒå…¥")
        
        if movie_id >= len(self.item_embeddings):
            return []
        
        # è®¡ç®—æ‰€æœ‰ç”µå½±ä¸ç›®æ ‡ç”µå½±çš„ç›¸ä¼¼åº¦
        similarities = cosine_similarity(
            [self.item_embeddings[movie_id]], 
            self.item_embeddings
        )[0]
        
        # æ’é™¤è‡ªå·±
        similarities[movie_id] = -1
        
        # è·å– top-k
        top_indices = np.argsort(similarities)[::-1][:top_k]
        top_scores = similarities[top_indices]
        
        return list(zip(top_indices.tolist(), top_scores.tolist()))
    
    def _get_popular_movies(self, top_k=10):
        """
        è·å–çƒ­é—¨ç”µå½±ï¼ˆåŸºäºè¯„åˆ†ç»Ÿè®¡ï¼‰

        è®¡ç®—é€»è¾‘ï¼š
        1. ç»Ÿè®¡æ¯éƒ¨ç”µå½±çš„è¯„åˆ†æ¬¡æ•°
        2. è®¡ç®—æ¯éƒ¨ç”µå½±çš„å¹³å‡è¯„åˆ†
        3. ç»¼åˆè¯„åˆ†æ¬¡æ•°å’Œå¹³å‡è¯„åˆ†è¿›è¡Œæ’åº
           - ç»¼åˆåˆ†æ•° = è¯„åˆ†æ¬¡æ•°æƒé‡ * log(è¯„åˆ†æ¬¡æ•°) + å¹³å‡è¯„åˆ†æƒé‡ * å¹³å‡è¯„åˆ†
        """
        if self.ratings_data is None:
            raise ValueError("éœ€è¦å…ˆè®­ç»ƒæ¨¡å‹ä»¥åŠ è½½è¯„åˆ†æ•°æ®")
        
        # ç»Ÿè®¡æ¯éƒ¨ç”µå½±çš„è¯„åˆ†æ¬¡æ•°å’Œæ€»åˆ†
        movie_stats = {}
        for user_id, item_id, rating in self.ratings_data:
            if item_id not in movie_stats:
                movie_stats[item_id] = {'count': 0, 'total': 0.0}
            movie_stats[item_id]['count'] += 1
            movie_stats[item_id]['total'] += rating
        
        # è®¡ç®—å¹³å‡è¯„åˆ†å’Œç»¼åˆåˆ†æ•°
        popular_movies = []
        for movie_id, stats in movie_stats.items():
            avg_rating = stats['total'] / stats['count']
            # ç»¼åˆåˆ†æ•°ï¼šç»“åˆè¯„åˆ†æ¬¡æ•°ï¼ˆçƒ­åº¦ï¼‰å’Œå¹³å‡è¯„åˆ†ï¼ˆè´¨é‡ï¼‰
            # ä½¿ç”¨ log(count) é¿å…è¯„åˆ†æ¬¡æ•°çš„å½±å“è¿‡å¤§
            popularity_score = 0.6 * np.log(stats['count']) + 0.4 * avg_rating
            popular_movies.append((movie_id, popularity_score, stats['count'], avg_rating))
        
        # æŒ‰ç»¼åˆåˆ†æ•°é™åºæ’åº
        popular_movies.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å› top-k
        return [(mid, float(score)) for mid, score, _, _ in popular_movies[:top_k]]
